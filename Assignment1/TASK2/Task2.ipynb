{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## TASK 2 - Image stitching\n",
    "\n",
    "Group Number: #INSERT HERE\n",
    "\n",
    "### 1. Data import and SIFT Extraction\n",
    "\n",
    "Complete ***get_panorama_data(..)*** in _dataset.py_ to read the images and extract the SIFT keypoints and descriptors per image. Check your implementation by plotting the result using ***utils.plot_keypoints(..)***.\n",
    "\n",
    "\n",
    "***Submission:*** Save the *second* image (from left) of the campus dataset as **task2_keypoints.png** using ***utils.plot_keypoints(..)***."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport transforms, panorama, mapping, dataset, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import transforms\n",
    "import panorama\n",
    "import mapping\n",
    "import dataset\n",
    "import utils\n",
    "import cv2\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8, 5]\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "data_path = 'data/office_rot'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#student_code start\n",
    "\n",
    "#student_code end\n",
    "\n",
    "# check import\n",
    "print('Number of images: ',len(images))\n",
    "print('Keypoints length: ', len(keypoints[0]))\n",
    "print('Descriptor shape: ',descriptors[0].shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "#### What is the meaning of the size of the drawn circles and lines inside the circles?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#ANSWER HERE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 Matching\n",
    "\n",
    "Let's take a look at the matching. Plot the matches between two adjacent images using ***mapping.calculate_matches(..)*** and ***utils.plot_matches(..)***.\n",
    "\n",
    "\n",
    "***Submission:*** Save plot of matches between the *second and the third image* image of the campus dataset as **task2_matches.png** using ***utils.plot_matches(..)***.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "index1 = 1\n",
    "index2 = 2\n",
    "\n",
    "#student_code start\n",
    "\n",
    "#student_code end"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "#### Describe below how the matching, based on LOWE, works."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#ANSWER HERE "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Image Registration using RANSAC\n",
    "\n",
    "As you can see in the keypoint matching plot above, the matching algorithm still has some wrong connections. To remove those outliers, you will implement RANSAC and use the remaining inliers to estimate a final tranformation matrix (homography) between two given images. Implement RANSAC in ***get_transform(..)*** in _transforms.py_.\n",
    "\n",
    "Check your implementation by plotting the result using ***utils.plot_matches(..)***.\n",
    "\n",
    "\n",
    "***Submission:*** Save a plot showing the matches between the *second and the third image* of the campus dataset again, using the calculated inliers, as **task2_matches_ransac.png** using ***utils.plot_matches(..)***."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "#student_code start\n",
    "\n",
    "#student_code end"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "#### What is the difference to the set of all putative matches you plotted before?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#ANSWER HERE "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 Align Images\n",
    "\n",
    "Test your homography after RANSAC by transforming a chosen image to the corresponding image on the right and plot with ***transforms.plot_transformed_image(..)***.\n",
    "\n",
    "_***HINT:***_\n",
    "_cv2.warpPerspective(..)_\n",
    "\n",
    "\n",
    "***Submission:*** Save the second image of the campus dataset transformed onto the third one as **task2_matches_transformed.png** using ***utils.plot_transformed_image(..)***."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#student_code start\n",
    "\n",
    "#student_code end"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Image Stitching\n",
    "\n",
    "Before, you implemented the basics to calculated homographies between two images. Further, transform all images to a reference image, usually the center one, to get a balanced panorama. Implement and use the method ***to_center(..)*** in _transforms.py_ to get all homographies to the center image.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#student_code start\n",
    "\n",
    "#student_code end"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Panorama Extents\n",
    "\n",
    "One final step before panorama composition is to estimate the final panorama size based on the obtained homographies. Implement ***transforms.get_panorama_extents(..)***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#student_code start\n",
    "\n",
    "\n",
    "\n",
    "#student_code end\n",
    "\n",
    "print(\"Panorama dimension: \", height, \" \",width)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Simple Panorama  \n",
    "\n",
    "Here is where the magic happens. Using the homographies, translation matrix and panorama extents, you can now stitch the images to a panorama. Implement ***panorama.get_simple(..)*** and check your result with ***utils.plot_panorama(..)***.\n",
    "\n",
    "***Submission:*** Save the campus panorama as **task2_panorama_simple.png** using ***utils.plot_panorama(..)***."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#student_code start\n",
    "\n",
    "#student_code end"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Panorama Feathering\n",
    "\n",
    "The simple panorama might look geometrically correct, but not pleasant enough yet. The intensities are simply stacked. Implement a color blending method to improve the panorama output. \n",
    "\n",
    "Complete ***panorama.get_blended(..)*** and check your result with ***utils.plot_panorama(..)***.\n",
    "\n",
    "***Submission:*** Save the improved blended campus panorama as **task2_panorama_blended.png** using ***utils.plot_panorama(..)***."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#student_code start\n",
    "\n",
    "#student_code end\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "#### Compare the result achieved with feathering to the result where no blending has been performed. What is the difference of the two results?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#ANSWER HERE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "#### Examine if the presented scheme of SIFT interest point detection and RANSAC-based alignment is invariant to changes in image rotation and scale. Thus, resize and rotate the second image of the campus dataset and repeat the panorama process. What do you observe?\n",
    "\n",
    "***Submission:*** Save the resulting panorama with the rotated images as file ***panorama_rotated_blended.png*** (feathered)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#ANSWER HERE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "#### Once again, repeat the panorama procedure with your own image sequence. Save and discuss the achieved results. The result might look quite realistic at a first glance but can you spot any errors by looking on details?\n",
    "\n",
    "***Submission:*** Save the resulting panorama as file ***panorama_own.png*** (feathered) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#ANSWER HERE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  },
  "interpreter": {
   "hash": "72251bb4b3de770cdd6b5816654bd6cf211b3b11a8abbaa61ae03430a7b8f87e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}